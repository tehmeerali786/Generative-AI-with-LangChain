{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9d2dfee-a0f8-4cb6-a3f5-a2227c9cc023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400d375-0e85-41ec-b473-1b27a10ba5c7",
   "metadata": {},
   "source": [
    "# Mittigating hallucination through fact-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f48ffe-843e-4496-843a-fd06fc88eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMCheckerChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dea1e36-f65c-4b4b-8b32-e84199aeff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0007bf7-7b40-4eb0-a53a-6272e8164599",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id = \"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff9e8cdd-3405-4bc5-aa85-71f810cbd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What type of mammal lays the biggest eggs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "321a258c-0ade-472b-a5aa-936ffde97df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker_chain = LLMCheckerChain.from_llm(llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6a6ce49-7984-4500-95e3-c7596f2e00fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What type of mammal lays the biggest eggs?',\n",
       " 'result': \"Here is a bullet point list of assertions:\\nHere is a statement:\\nWhat type of mammal lays the biggest eggs?\\n\\nThe largest egg laid by a mammal is that of the echidna. The echidna is a type of egg-laying mammal that is found in Australia and New Guinea. The echidna's egg is about the size of a ping pong ball and is covered in a leathery shell.\\nMake a bullet point list of the assumptions you made when producing the above statement.\\n\\n1. The largest egg laid by a mammal is the echidna egg.\\n2. The echidna is a type of egg-laying mammal.\\n3. The echidna is found in Australia and New Guinea.\\n4. The echidna egg is about the size of a ping pong ball.\\n5. The echidna egg is covered in a leathery shell.\\n6. The echidna is a type of egg-laying mammal that is found in\\nFor each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n1. True\\n2. True\\n3. True\\n4. True\\n5. True\\n6. True\\nFor each assumption, determine whether it is true or false. If it is false, explain why.\\n\\n1. True\\n2. True\\n3. True\\n4. True\\n5. True\\n6. True\\nFor each statement, determine whether it is true or false. If it is false, explain why.\\n\\n1. True\\n2. True\\n3.\\n\\nQuestion: In light of the above assertions and checks, how would you answer the question 'What type of mammal lays the biggest eggs?'?\\n\\nAnswer: The echidna is a type of egg-laying mammal that is found in Australia and New Guinea. The echidna's egg is about the size of a ping pong ball and is covered in a leathery shell.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker_chain(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc5f049-d419-40d7-8394-e3a316c765d8",
   "metadata": {},
   "source": [
    "# Summarizing Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5baa65-7446-42a7-803a-27eab9b0901e",
   "metadata": {},
   "source": [
    "## Basic prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70841dc2-79dd-4b20-9af8-1f91b1b6b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b68f3af-c9cf-4fab-945e-05bff026de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79413428-5e57-48e2-b867-0621004c5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Summarize this text in one sentence.\n",
    "\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa69e190-f192-4a61-a98e-f7d18b6b2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" Nelva Williamson has been a teacher in Houston for more than 40 years. Two years ago, she began teaching AP African American studies and Williamson told CNN during her lectures she can see her students have “lightbulb moments.”\n",
    "\n",
    "“I teach that [African Americans] did not start enslaved. There’s greatness in African kingdoms,” Williamson said. She said that students feel uplifted when they learn about Black history predating racial oppression in the United States.\n",
    "\n",
    "Williamson said the class is empowering for her students, who are predominantly Black and brown girls.\n",
    "\n",
    "But she’s also teaching AP African American Studies amid a nationwide debates over how topics like race, racism and sexuality are taught in American classrooms.\n",
    "\n",
    "According to a new survey published Thursday by the Pew Research Center, 41% of teachers surveyed said these nationwide debates have had a negative impact on their ability to do their job.\n",
    "And as the parental rights movement continues to gain momentum in some states, 60% of public K-12 teachers surveyed said parents should not be able to opt their children out of learning about racial inequality or racism, even if it conflicts with the parents’ beliefs.\n",
    "\n",
    "Forty-eight percent of public K-12 teachers surveyed said parents should be allowed to opt out of lessons on gender identity or sexual orientation.\n",
    "\n",
    "Williamson said she feels students should learn about race and racial inequality that has occurred throughout history within the context of the state standards.\n",
    "\n",
    "“By opting out of these discussions, students are not learning the full depth and breadth of the history of this nation and the world,” Williamson told CNN. “To be opting out of that classroom discussion would be to put blinders on regarding the impact of race around the world.”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8559608c-f037-425c-936b-5fe1613d26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = llm(prompt.format(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8e0994e-f7b2-4809-aa28-d8a8ac9c6a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Pew Research Center released a new survey Thursday that found 41% of teachers say nationwide debates over how topics like race, racism and sexuality are taught in American classrooms have had a negative impact on their ability to do their job.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05149bcd-ea5b-4d81-bf15-e1a796a4f082",
   "metadata": {},
   "source": [
    "## Prompt decoraters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cba3855-e532-41dd-8a1f-dcea503086a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_decorators import GlobalSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4ff9eda-f0f8-48e8-acf3-14778525c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalSettings.define_settings(\n",
    "    default_llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\"),\n",
    "    default_streaming_llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79af72db-e795-4383-9e3e-21a0d9793f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_decorators import llm_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "306a52ec-6d5b-43ce-b302-74b073c511b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@llm_prompt \n",
    "def summarize(text:str, length=\"short\") -> str:\n",
    "    \"\"\" \n",
    "    Summarize this text in {length} length:\n",
    "\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4591265d-d619-474f-8dd9-0270fd2373dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarize(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2294fb7-ea50-45fd-90ff-8a1b5dc164cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Pew Research Center released a new survey Thursday that found 41% of teachers say nationwide debates over how topics like race, racism and sexuality are taught in American classrooms have had a negative impact on their ability to do their job.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705fb41a-722d-497f-a3c3-969bc3a99690",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d0c0d90-ea0a-4b31-a822-73e1b195be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I. Introduction\n",
    "Large language models (LLMs) present a new opportunity for CAD software companies to enhance design workflows through conversational AI. Rather than navigating complex menus, engineers can describe needs in plain language and receive intelligent responses powered by integrated data.\n",
    "For example, an engineer could query a parts database by asking for “aluminum brackets under 2 ounces.” The LLM would understand the specifications and return matching components by searching the catalog. Users can get information easily without navigating through static sources.\n",
    "LLMs leverage natural language understanding to open up knowledge on-demand. This self-service approach provides faster answers, drives recurring use, and monetizes integrated data assets. AI transforms CAD from a passive tool to a conversant one.\n",
    "II. Streamlining Workflows with Conversational CAD\n",
    "CAD software is known for its intricate menu-driven processes. However, integrating AI-driven natural language interaction has the potential to streamline and automate routine tasks, simplifying the user experience and boosting efficiency.\n",
    "Generative AI has the potential to change the anatomy of work, augmenting the capabilities of individual workers by automating some of their individual activities. Source: Mckinsey Digital\n",
    "III Design Changes:\n",
    "The AI-driven CAD tool empowers users to transform their design concepts into reality by describing their intentions. For instance, consider an individual crafting a robot; they can detail their desired robot appearance, and the tool will generate a corresponding 3D model. For instance, they can specify features like two flexible arms, wheeled legs, a square body, and a domed head with camera “eyes”. The AI responds with an initial design, aiding the user’s starting point.\n",
    "More significantly, the AI collaborates with users to enhance existing designs. Examples include:\n",
    "- “Locate 4-inch diameter wheels”\n",
    "AI searches a database and presents suitable options for selection.\n",
    "- “Opt for the 2nd choice”\n",
    "AI implements the chosen option, providing further details if necessary.\n",
    "- “Attach the wheel to the front-left A-frame at the 2nd hole”\n",
    "AI adds the wheel as specified, illustrating the updated design.\n",
    "This interactive experience truly helps users to get an early prototype done on time.\n",
    "\n",
    "IV Design Reviews:\n",
    "During the process of design reviews, AI plays a pivotal role in providing valuable insights and enhancing decision-making. By addressing crucial questions and concerns, AI brings an intelligent dimension to the design process.\n",
    "Here are some examples of design review questions which AI can help with.\n",
    "- “Is the weight distribution even?”\n",
    "AI conducts thorough analysis, presenting a heatmap of weight distribution, and suggests corrective measures.\n",
    "- “Where’s the center of mass?”\n",
    "AI graphically indicates the center of mass coordinates on your CAD drawing, aiding in precise design adjustments.\n",
    "- “What’s the best arm position for balance?”\n",
    "AI visually pinpoints optimal arm positions on your CAD drawing and provides explanatory rationale.\n",
    "- “Any duplicate or disconnected parts?”\n",
    "AI effectively highlights duplicate or disconnected components, accompanied by recommended steps for resolution.\n",
    "\n",
    "Through these AI-assisted functionalities, design reviews become more comprehensive, efficient, and insightful. AI’s visual representations and recommendations significantly contribute to the refinement and advancement of the design process.\n",
    "V. Performance Analysis\n",
    "Before the design can be implemented, its important to do performance analysis of the design to see if its able to take the load. These are the questions one could ask for the AI to do those analysis and respond back with results of the simulation.\n",
    "- “How’s the weight split with 20lb added in front?”\n",
    "AI checks the balance and visually shows if the weight is even or if adjustments are needed using a heatmap.\n",
    "- “Will it topple if a 0.5lb weight is lifted 10 inches out?”\n",
    "AI shows the torque applied and shows if the design will tip over with the weight lifted\n",
    "- “Will it topple at 3 in/sec with the arm extended?”\n",
    "AI figures out if the design can stay steady while moving at that speed with the arm out.\n",
    "These questions truly help save so much time to simulate the robot with real expected loads and tweak the design before we actually build the robot.\n",
    "VI. Conversational CAD for Agile Design\n",
    "The ability to make rapid design changes through conversation represents a major opportunity for CAD software. Engineers could instantly modify models by describing needs instead of reworking manually.\n",
    "For example, if a specific part is not available during prototyping, an engineer could ask the CAD system to replace it with an alternate meeting certain specs. The software would swap the component and rerun analyses to validate the design integrity is maintained.\n",
    "Integrating language interaction powered by large language models will transform the user experience and vastly expand accessibility\n",
    "Rather than redoing work, the engineer can make changes conversationally and get rapid feedback. This enables more agile design iterations and testing compared to rigid static workflows.\n",
    "Intelligent CAD systems that can understand descriptive change requests and assess impacts will enable faster experimentation. Conversation powers more flexible and nimble product development, unlocking the full potential of digital design tools.\n",
    "VII. Monetizing Integrated Data\n",
    "A major incentive for CAD companies is monetizing integrated proprietary data like parts libraries, materials specifications, physics simulation results, and testing data.\n",
    "Rather than siloed databases, conversational AI unlocks this knowledge on-demand. Customers get faster answers while driving engagement and recurring revenue.\n",
    "With natural language interfaces, users can tap into integrated data conversationally instead of combing through manuals or passive reports. Conversational CAD provides engaging self-service access to proprietary engineering knowledge.\n",
    "VIII. Flexible Pricing for Conversational Interactions\n",
    "Conversational capabilities open creative pricing approaches:\n",
    "- Charge per conversational query as a microtransaction\n",
    "- Offer bundles or subscriptions for unlimited queries\n",
    "- Provide a limited queries tier then paid options\n",
    "- Charge for API access enabling conversational apps\n",
    "- Limit advanced conversational features to premium tiers\n",
    "These conversational capabilities not only offer innovative pricing avenues but also pave the way for new and imaginative models that extend beyond the confines of traditional CAD licensing. The diverse options, from microtransactions to premium tiers, harness the true value of conversational interactions, shaping a dynamic landscape for the future of CAD software access.\n",
    "IX. The Future of Intelligent CAD\n",
    "Many CAD systems today still rely heavily on complex manual menus and workflows that can hinder design agility. But forward-looking CAD companies have an opportunity to disrupt the status quo by incorporating conversational AI.\n",
    "Natural language interaction would allow engineers to tap into integrated engineering knowledge and rapidly automate tasks by describing them conversationally. Intelligent CAD systems would enhance design, analysis, and collaboration while opening new ways to monetize proprietary data assets.\n",
    "The ultimate vision is an augmented CAD experience with AI as an active collaborator:\n",
    "- Engineers conversing with context-aware, conversational interfaces\n",
    "- CAD systems proactively surfacing insights from integrated multi-disciplinary data\n",
    "- Automating repetitive tasks through conversational requests\n",
    "- Democratizing best practices embedded in CAD data to all user levels\n",
    "- Scaling expertise through AI-recommended design improvements\n",
    "- Fostering better human-to-human collaboration around digital models\n",
    "This future of intelligent CAD powered by conversational AI and data unlocks immense potential. CAD evolves from passive software to an active collaborator amplifying human creativity and ingenuity. Conversational CAD promises to revolutionize the practice of engineering itself.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e83cf97-9a11-423d-937d-123bd958e2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "967a8689-75c8-448f-83ea-607ed1b4ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub\n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95ce2461-7484-45ef-b66f-261b8304528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceHub(repo_id = \"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7735eff-b9ee-4e22-a5c6-c2e9be1b3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.chat_models import JinaChat\n",
    "# llm = JinaChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f017d85e-7fb0-4102-8d5d-4eb9f43520b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e25afbf8-6d5d-4e08-8983-e92859f4ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Summarize this text: {text}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cece5ca-e7ae-4445-9667-068dc4866248",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03ba7a8c-47cb-4237-a252-363ffab1cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = runnable.invoke({\"text\" : text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cab427fa-92ad-4ce7-b263-02b6e036db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversational AI, powered by Large Language Models (LLMs), is transforming CAD software, enabling engineers to interact with it using natural language. This streamlines workflows by automating routine tasks and simplifying user experiences. AI-driven CAD tools empower users to describe design concepts and generate 3D models, collaborate on design changes, and conduct performance analysis through conversational queries. Conversational interfaces also unlock monetization opportunities for CAD companies by providing on-demand access to integrated data assets. Flexible pricing models based on conversational interactions further enhance the value proposition. Intelligent CAD systems will continue to evolve, offering augmented experiences with AI as a collaborator, automating tasks, surfacing insights, and democratizing best practices. Conversational CAD promises to revolutionize engineering practices by enhancing creativity, collaboration, and efficiency.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7e6f5-db63-44c3-ab0f-67ec48dcfb0e",
   "metadata": {},
   "source": [
    "## Chain of Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "631fa5cb-6123-419c-a414-ab2ace2cf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = \"\"\"I. Introduction\n",
    "Large language models (LLMs) present a new opportunity for CAD software companies to enhance design workflows through conversational AI. Rather than navigating complex menus, engineers can describe needs in plain language and receive intelligent responses powered by integrated data.\n",
    "For example, an engineer could query a parts database by asking for “aluminum brackets under 2 ounces.” The LLM would understand the specifications and return matching components by searching the catalog. Users can get information easily without navigating through static sources.\n",
    "LLMs leverage natural language understanding to open up knowledge on-demand. This self-service approach provides faster answers, drives recurring use, and monetizes integrated data assets. AI transforms CAD from a passive tool to a conversant one.\n",
    "II. Streamlining Workflows with Conversational CAD\n",
    "CAD software is known for its intricate menu-driven processes. However, integrating AI-driven natural language interaction has the potential to streamline and automate routine tasks, simplifying the user experience and boosting efficiency.\n",
    "Generative AI has the potential to change the anatomy of work, augmenting the capabilities of individual workers by automating some of their individual activities. Source: Mckinsey Digital\n",
    "III Design Changes:\n",
    "The AI-driven CAD tool empowers users to transform their design concepts into reality by describing their intentions. For instance, consider an individual crafting a robot; they can detail their desired robot appearance, and the tool will generate a corresponding 3D model. For instance, they can specify features like two flexible arms, wheeled legs, a square body, and a domed head with camera “eyes”. The AI responds with an initial design, aiding the user’s starting point.\n",
    "More significantly, the AI collaborates with users to enhance existing designs. Examples include:\n",
    "- “Locate 4-inch diameter wheels”\n",
    "AI searches a database and presents suitable options for selection.\n",
    "- “Opt for the 2nd choice”\n",
    "AI implements the chosen option, providing further details if necessary.\n",
    "- “Attach the wheel to the front-left A-frame at the 2nd hole”\n",
    "AI adds the wheel as specified, illustrating the updated design.\n",
    "This interactive experience truly helps users to get an early prototype done on time.\n",
    "\n",
    "IV Design Reviews:\n",
    "During the process of design reviews, AI plays a pivotal role in providing valuable insights and enhancing decision-making. By addressing crucial questions and concerns, AI brings an intelligent dimension to the design process.\n",
    "Here are some examples of design review questions which AI can help with.\n",
    "- “Is the weight distribution even?”\n",
    "AI conducts thorough analysis, presenting a heatmap of weight distribution, and suggests corrective measures.\n",
    "- “Where’s the center of mass?”\n",
    "AI graphically indicates the center of mass coordinates on your CAD drawing, aiding in precise design adjustments.\n",
    "- “What’s the best arm position for balance?”\n",
    "AI visually pinpoints optimal arm positions on your CAD drawing and provides explanatory rationale.\n",
    "- “Any duplicate or disconnected parts?”\n",
    "AI effectively highlights duplicate or disconnected components, accompanied by recommended steps for resolution.\n",
    "\n",
    "Through these AI-assisted functionalities, design reviews become more comprehensive, efficient, and insightful. AI’s visual representations and recommendations significantly contribute to the refinement and advancement of the design process.\n",
    "V. Performance Analysis\n",
    "Before the design can be implemented, its important to do performance analysis of the design to see if its able to take the load. These are the questions one could ask for the AI to do those analysis and respond back with results of the simulation.\n",
    "- “How’s the weight split with 20lb added in front?”\n",
    "AI checks the balance and visually shows if the weight is even or if adjustments are needed using a heatmap.\n",
    "- “Will it topple if a 0.5lb weight is lifted 10 inches out?”\n",
    "AI shows the torque applied and shows if the design will tip over with the weight lifted\n",
    "- “Will it topple at 3 in/sec with the arm extended?”\n",
    "AI figures out if the design can stay steady while moving at that speed with the arm out.\n",
    "These questions truly help save so much time to simulate the robot with real expected loads and tweak the design before we actually build the robot.\n",
    "VI. Conversational CAD for Agile Design\n",
    "The ability to make rapid design changes through conversation represents a major opportunity for CAD software. Engineers could instantly modify models by describing needs instead of reworking manually.\n",
    "For example, if a specific part is not available during prototyping, an engineer could ask the CAD system to replace it with an alternate meeting certain specs. The software would swap the component and rerun analyses to validate the design integrity is maintained.\n",
    "Integrating language interaction powered by large language models will transform the user experience and vastly expand accessibility\n",
    "Rather than redoing work, the engineer can make changes conversationally and get rapid feedback. This enables more agile design iterations and testing compared to rigid static workflows.\n",
    "Intelligent CAD systems that can understand descriptive change requests and assess impacts will enable faster experimentation. Conversation powers more flexible and nimble product development, unlocking the full potential of digital design tools.\n",
    "VII. Monetizing Integrated Data\n",
    "A major incentive for CAD companies is monetizing integrated proprietary data like parts libraries, materials specifications, physics simulation results, and testing data.\n",
    "Rather than siloed databases, conversational AI unlocks this knowledge on-demand. Customers get faster answers while driving engagement and recurring revenue.\n",
    "With natural language interfaces, users can tap into integrated data conversationally instead of combing through manuals or passive reports. Conversational CAD provides engaging self-service access to proprietary engineering knowledge.\n",
    "VIII. Flexible Pricing for Conversational Interactions\n",
    "Conversational capabilities open creative pricing approaches:\n",
    "- Charge per conversational query as a microtransaction\n",
    "- Offer bundles or subscriptions for unlimited queries\n",
    "- Provide a limited queries tier then paid options\n",
    "- Charge for API access enabling conversational apps\n",
    "- Limit advanced conversational features to premium tiers\n",
    "These conversational capabilities not only offer innovative pricing avenues but also pave the way for new and imaginative models that extend beyond the confines of traditional CAD licensing. The diverse options, from microtransactions to premium tiers, harness the true value of conversational interactions, shaping a dynamic landscape for the future of CAD software access.\n",
    "IX. The Future of Intelligent CAD\n",
    "Many CAD systems today still rely heavily on complex manual menus and workflows that can hinder design agility. But forward-looking CAD companies have an opportunity to disrupt the status quo by incorporating conversational AI.\n",
    "Natural language interaction would allow engineers to tap into integrated engineering knowledge and rapidly automate tasks by describing them conversationally. Intelligent CAD systems would enhance design, analysis, and collaboration while opening new ways to monetize proprietary data assets.\n",
    "The ultimate vision is an augmented CAD experience with AI as an active collaborator:\n",
    "- Engineers conversing with context-aware, conversational interfaces\n",
    "- CAD systems proactively surfacing insights from integrated multi-disciplinary data\n",
    "- Automating repetitive tasks through conversational requests\n",
    "- Democratizing best practices embedded in CAD data to all user levels\n",
    "- Scaling expertise through AI-recommended design improvements\n",
    "- Fostering better human-to-human collaboration around digital models\n",
    "This future of intelligent CAD powered by conversational AI and data unlocks immense potential. CAD evolves from passive software to an active collaborator amplifying human creativity and ingenuity. Conversational CAD promises to revolutionize the practice of engineering itself.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8936c510-7f53-434f-9762-5d2d6c00c4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593ba26b-2951-415b-9e58-01031cf0b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feff9956-dae6-4d1c-8e86-5cfa921dd7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceHub(repo_id = \"google/gemma-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f4b1ef3-9c92-4721-95a5-d54b854b4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2125a68-ba95-42ec-9050-2e105bd7e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Article: {article_text} \n",
    "You will generate interestingly concise, entity-dense summaries of the above article. \n",
    "Repeat the following 2 steps 5 times.\n",
    "Step 1: Identify 1-3 informative (\";\" delimited) from the article which are missing from the previously generated summary.\n",
    "Step 2: Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities.\n",
    "A missing entity is:\n",
    " - relevant to the main story,\n",
    " - specific yet concise (5 words or fewer)\n",
    " - novel (not in the previous summary),\n",
    " - faithful (present in the article),\n",
    " - anywhere (can be located anywhere in the article).\n",
    " \n",
    "Guidlines:\n",
    " - The first summary should be long (4-5 sentences, ~80words) yet highly non-specific, containing little information beyond the entities marked as missing.\n",
    "   Use overly verbose language and filters (e.g., \"this arcile discusses\") to reach ~80 words.\n",
    " - Make every word count: rewrite the previous summary to improve flow and make space for additional entities. \n",
    " - Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    " - The summaries should become highly dense and concise yet self-contained, i.e., easily undersood without the article.\n",
    " - Missing entities can appear anywhere in the new summary.\n",
    " - Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
    "\n",
    "Remember use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\". \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4fe5eff-6922-4ad5-b9c8-6003eb9a5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate \n",
    "from langchain.schema import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ce2639a-2194-4502-936c-e96296f08ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2191b447-3a00-47cb-8882-7a6f5be89331",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e459c11b-38d4-44fa-a146-ba20e2acecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = runnable.invoke({\"article_text\":article_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22d6489f-ffad-4e6d-83d1-fcb63b75a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n[\\n  {\\n    \"Missing_Entities\": \"conversational AI; CAD software; design workflows\",\\n    \"Denser_Summary\": \"This article discusses the integration of conversational AI into CAD software to enhance design workflows. By leveraging natural language understanding, engineers can use plain language to query parts databases, streamline routine tasks, and transform design concepts into reality.\"\\n  },\\n  {\\n    \"Missing_Entities\": \"self-service approach; monetization; integrated data assets\",\\n    \"Denser_Summary\": \"Conversational AI in CAD software provides a self-service approach, enabling faster answers, driving recurring use, and monetizing integrated data assets. It transforms CAD from a passive tool to a conversant one, empowering users to access knowledge on-demand and enhance design reviews.\"\\n  },\\n  {\\n    \"Missing_Entities\": \"generative AI; anatomy of work; individual activities\",\\n    \"Denser_Summary\": \"Generative AI in CAD software augments individual capabilities by automating activities, streamlining workflows, and simplifying the user experience. It empowers users to transform their design concepts into reality by describing their intentions, fostering collaboration, and enhancing design reviews through valuable insights and visual representations.\"\\n  },\\n  {\\n    \"Missing_Entities\": \"performance analysis; torque; center of mass\",\\n    \"Denser_Summary\": \"Conversational AI in CAD software enables performance analysis, allowing users to assess weight distribution, center of mass, and stability. By simulating real-world loads and providing visual representations, it helps users refine designs and make informed decisions, saving time and resources.\"\\n  },\\n  {\\n    \"Missing_Entities\": \"agile design; rapid design changes; experimentations\",\\n    \"Denser_Summary\": \"Conversational AI in CAD software supports agile design, enabling rapid design changes through natural language descriptions. It empowers engineers to make modifications instantly, swap components, and rerun analyses, fostering more flexible and nimble product development.\"\\n  }\\n]\\n```'\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3648c-0699-4f02-8c09-267b26b17a2b",
   "metadata": {},
   "source": [
    "## Map and Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d554764c-c66f-4edd-aef8-5c7ca6b29e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07aafb9f-97d4-4825-b79f-4a67d6495f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_google_genai import  ChatGoogleGenerativeAI \n",
    "from langchain.document_loaders import PyPDFLoader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b84543-85bd-4bda-9090-5fe659247d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"Selling.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1305f1c1-51be-4af0-94be-72e5a1732aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd7905e-2c2e-454b-92a8-6088bd01fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77e29ec7-071b-4042-9804-2fa56af31193",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a075cbc-67a7-48fa-a03b-064a81d60577",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7de72af-e119-4b22-bcb8-cb57248408c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Terry Dean's marketing guide provides a comprehensive formula for attracting clients, creating passive income, and making a positive impact. It emphasizes delivering value, building relationships, and using ethical persuasion techniques. The guide covers strategies for lead generation, content marketing, email marketing, paid advertising, and strategic partnerships, emphasizing the importance of a strong brand identity and storytelling. It also includes practical advice on creating irresistible offers, eliminating sales resistance, and using proven persuasion formulas. The guide encourages businesses to embrace unconventional strategies, establish authority, and build an email list for effective client acquisition. By understanding target audiences, leveraging the Hero's Journey narrative, and implementing advanced retargeting campaigns, businesses can attract ideal clients, generate revenue, and create a loyal customer base.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ee427-c729-4787-807e-c315948d9876",
   "metadata": {},
   "source": [
    "## Monitoring Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59253ba3-2e2e-430c-8566-28bca1d1fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb93cf9d-1cdf-498f-8af0-0f2ac8829128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73baf23c-7b21-4fd3-8f91-cd43f3adf4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'AsyncIteratorCallbackHandler',\n",
       " 'FileCallbackHandler',\n",
       " 'FinalStreamingStdOutCallbackHandler',\n",
       " 'LangChainDeprecationWarning',\n",
       " 'LangChainTracer',\n",
       " 'StdOutCallbackHandler',\n",
       " 'StreamingStdOutCallbackHandler',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'collect_runs',\n",
       " 'file',\n",
       " 'is_interactive_env',\n",
       " 'manager',\n",
       " 'streaming_aiter',\n",
       " 'streaming_stdout_final_only',\n",
       " 'tracing_enabled',\n",
       " 'tracing_v2_enabled',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(langchain.callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a40ad61-817e-4b49-95e3-3cf3824d9235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AsyncCallbackManager',\n",
       " 'AsyncCallbackManagerForChainGroup',\n",
       " 'AsyncCallbackManagerForChainRun',\n",
       " 'AsyncCallbackManagerForLLMRun',\n",
       " 'AsyncCallbackManagerForRetrieverRun',\n",
       " 'AsyncCallbackManagerForToolRun',\n",
       " 'AsyncParentRunManager',\n",
       " 'AsyncRunManager',\n",
       " 'BaseRunManager',\n",
       " 'CallbackManager',\n",
       " 'CallbackManagerForChainGroup',\n",
       " 'CallbackManagerForChainRun',\n",
       " 'CallbackManagerForLLMRun',\n",
       " 'CallbackManagerForRetrieverRun',\n",
       " 'CallbackManagerForToolRun',\n",
       " 'Callbacks',\n",
       " 'ParentRunManager',\n",
       " 'RunManager',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'ahandle_event',\n",
       " 'annotations',\n",
       " 'atrace_as_chain_group',\n",
       " 'collect_runs',\n",
       " 'env_var_is_set',\n",
       " 'get_openai_callback',\n",
       " 'handle_event',\n",
       " 'trace_as_chain_group',\n",
       " 'tracing_enabled',\n",
       " 'tracing_v2_enabled',\n",
       " 'wandb_tracing_enabled']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(langchain.callbacks.manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4a042-0cca-4c57-b2bf-e31339e69d74",
   "metadata": {},
   "source": [
    "## Miscellaneous Prompts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f1543-3d98-44f7-9ab7-bb6637e30029",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1373dc18-9d7d-45f8-a99a-97df62a31570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6633b96-3896-4c5a-bdb8-76a76eb7bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562a30d6-2e5d-4b86-baca-687f711c28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I. Introduction\n",
    "Large language models (LLMs) present a new opportunity for CAD software companies to enhance design workflows through conversational AI. Rather than navigating complex menus, engineers can describe needs in plain language and receive intelligent responses powered by integrated data.\n",
    "For example, an engineer could query a parts database by asking for “aluminum brackets under 2 ounces.” The LLM would understand the specifications and return matching components by searching the catalog. Users can get information easily without navigating through static sources.\n",
    "LLMs leverage natural language understanding to open up knowledge on-demand. This self-service approach provides faster answers, drives recurring use, and monetizes integrated data assets. AI transforms CAD from a passive tool to a conversant one.\n",
    "II. Streamlining Workflows with Conversational CAD\n",
    "CAD software is known for its intricate menu-driven processes. However, integrating AI-driven natural language interaction has the potential to streamline and automate routine tasks, simplifying the user experience and boosting efficiency.\n",
    "Generative AI has the potential to change the anatomy of work, augmenting the capabilities of individual workers by automating some of their individual activities. Source: Mckinsey Digital\n",
    "III Design Changes:\n",
    "The AI-driven CAD tool empowers users to transform their design concepts into reality by describing their intentions. For instance, consider an individual crafting a robot; they can detail their desired robot appearance, and the tool will generate a corresponding 3D model. For instance, they can specify features like two flexible arms, wheeled legs, a square body, and a domed head with camera “eyes”. The AI responds with an initial design, aiding the user’s starting point.\n",
    "More significantly, the AI collaborates with users to enhance existing designs. Examples include:\n",
    "- “Locate 4-inch diameter wheels”\n",
    "AI searches a database and presents suitable options for selection.\n",
    "- “Opt for the 2nd choice”\n",
    "AI implements the chosen option, providing further details if necessary.\n",
    "- “Attach the wheel to the front-left A-frame at the 2nd hole”\n",
    "AI adds the wheel as specified, illustrating the updated design.\n",
    "This interactive experience truly helps users to get an early prototype done on time.\n",
    "\n",
    "IV Design Reviews:\n",
    "During the process of design reviews, AI plays a pivotal role in providing valuable insights and enhancing decision-making. By addressing crucial questions and concerns, AI brings an intelligent dimension to the design process.\n",
    "Here are some examples of design review questions which AI can help with.\n",
    "- “Is the weight distribution even?”\n",
    "AI conducts thorough analysis, presenting a heatmap of weight distribution, and suggests corrective measures.\n",
    "- “Where’s the center of mass?”\n",
    "AI graphically indicates the center of mass coordinates on your CAD drawing, aiding in precise design adjustments.\n",
    "- “What’s the best arm position for balance?”\n",
    "AI visually pinpoints optimal arm positions on your CAD drawing and provides explanatory rationale.\n",
    "- “Any duplicate or disconnected parts?”\n",
    "AI effectively highlights duplicate or disconnected components, accompanied by recommended steps for resolution.\n",
    "\n",
    "Through these AI-assisted functionalities, design reviews become more comprehensive, efficient, and insightful. AI’s visual representations and recommendations significantly contribute to the refinement and advancement of the design process.\n",
    "V. Performance Analysis\n",
    "Before the design can be implemented, its important to do performance analysis of the design to see if its able to take the load. These are the questions one could ask for the AI to do those analysis and respond back with results of the simulation.\n",
    "- “How’s the weight split with 20lb added in front?”\n",
    "AI checks the balance and visually shows if the weight is even or if adjustments are needed using a heatmap.\n",
    "- “Will it topple if a 0.5lb weight is lifted 10 inches out?”\n",
    "AI shows the torque applied and shows if the design will tip over with the weight lifted\n",
    "- “Will it topple at 3 in/sec with the arm extended?”\n",
    "AI figures out if the design can stay steady while moving at that speed with the arm out.\n",
    "These questions truly help save so much time to simulate the robot with real expected loads and tweak the design before we actually build the robot.\n",
    "VI. Conversational CAD for Agile Design\n",
    "The ability to make rapid design changes through conversation represents a major opportunity for CAD software. Engineers could instantly modify models by describing needs instead of reworking manually.\n",
    "For example, if a specific part is not available during prototyping, an engineer could ask the CAD system to replace it with an alternate meeting certain specs. The software would swap the component and rerun analyses to validate the design integrity is maintained.\n",
    "Integrating language interaction powered by large language models will transform the user experience and vastly expand accessibility\n",
    "Rather than redoing work, the engineer can make changes conversationally and get rapid feedback. This enables more agile design iterations and testing compared to rigid static workflows.\n",
    "Intelligent CAD systems that can understand descriptive change requests and assess impacts will enable faster experimentation. Conversation powers more flexible and nimble product development, unlocking the full potential of digital design tools.\n",
    "VII. Monetizing Integrated Data\n",
    "A major incentive for CAD companies is monetizing integrated proprietary data like parts libraries, materials specifications, physics simulation results, and testing data.\n",
    "Rather than siloed databases, conversational AI unlocks this knowledge on-demand. Customers get faster answers while driving engagement and recurring revenue.\n",
    "With natural language interfaces, users can tap into integrated data conversationally instead of combing through manuals or passive reports. Conversational CAD provides engaging self-service access to proprietary engineering knowledge.\n",
    "VIII. Flexible Pricing for Conversational Interactions\n",
    "Conversational capabilities open creative pricing approaches:\n",
    "- Charge per conversational query as a microtransaction\n",
    "- Offer bundles or subscriptions for unlimited queries\n",
    "- Provide a limited queries tier then paid options\n",
    "- Charge for API access enabling conversational apps\n",
    "- Limit advanced conversational features to premium tiers\n",
    "These conversational capabilities not only offer innovative pricing avenues but also pave the way for new and imaginative models that extend beyond the confines of traditional CAD licensing. The diverse options, from microtransactions to premium tiers, harness the true value of conversational interactions, shaping a dynamic landscape for the future of CAD software access.\n",
    "IX. The Future of Intelligent CAD\n",
    "Many CAD systems today still rely heavily on complex manual menus and workflows that can hinder design agility. But forward-looking CAD companies have an opportunity to disrupt the status quo by incorporating conversational AI.\n",
    "Natural language interaction would allow engineers to tap into integrated engineering knowledge and rapidly automate tasks by describing them conversationally. Intelligent CAD systems would enhance design, analysis, and collaboration while opening new ways to monetize proprietary data assets.\n",
    "The ultimate vision is an augmented CAD experience with AI as an active collaborator:\n",
    "- Engineers conversing with context-aware, conversational interfaces\n",
    "- CAD systems proactively surfacing insights from integrated multi-disciplinary data\n",
    "- Automating repetitive tasks through conversational requests\n",
    "- Democratizing best practices embedded in CAD data to all user levels\n",
    "- Scaling expertise through AI-recommended design improvements\n",
    "- Fostering better human-to-human collaboration around digital models\n",
    "This future of intelligent CAD powered by conversational AI and data unlocks immense potential. CAD evolves from passive software to an active collaborator amplifying human creativity and ingenuity. Conversational CAD promises to revolutionize the practice of engineering itself.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "552ff8ee-e70a-4fd9-8b12-819533ee9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = ( \n",
    "    \"\"\"Give me a clear explanation of the objectives, core assertion, implications, and mechanics elucidated in this text - remove\n",
    "        citations! \\n\"\"\"\n",
    "    \"{text} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d2b5547-05db-40ce-b2fa-4fea17ac84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "00ed3e29-f3fb-4118-831d-18d2d2c749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "372a30b1-537d-40fb-b901-9b10e6c0e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47333c25-0452-4ffa-bbd5-ef46ecdc202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = runnable.invoke({\"text\" : text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "65db93cd-468e-4883-9767-278e5f8b0ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Objectives:**\\n\\n* Enhance design workflows with conversational AI.\\n* Simplify user experience and boost efficiency.\\n* Transform CAD from a passive tool to a conversant one.\\n* Monetize integrated proprietary data.\\n\\n**Core Assertion:**\\n\\nConversational AI integrated into CAD software allows engineers to describe their needs in plain language and receive intelligent responses, empowering them to design and analyze faster and more effectively.\\n\\n**Implications:**\\n\\n* Streamlines workflows through AI-driven natural language interaction.\\n* Enables users to transform design concepts into reality by describing their intentions.\\n* Provides valuable insights and enhances decision-making during design reviews.\\n* Facilitates performance analysis by enabling engineers to ask questions about design stability and performance.\\n* Allows for agile design iterations and testing through conversational changes.\\n\\n**Mechanics:**\\n\\n* **Natural language understanding:** AI understands specifications and returns matching components by searching the catalog.\\n* **Generative AI:** AI generates 3D models based on user descriptions.\\n* **Interactive experience:** Users can refine designs by providing further instructions conversationally.\\n* **Design analysis:** AI conducts analysis and presents insights visually, aiding in design adjustments.\\n* **Performance analysis:** AI simulates designs under various loads and provides results.\\n* **Monetization:** Conversational capabilities enable creative pricing approaches, such as microtransactions and subscription models.'\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4bf90-18df-4602-96c7-417dbacf5ec5",
   "metadata": {},
   "source": [
    "### High Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9822d16-3e10-40f5-a937-328d42402fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_LEVEL = (\n",
    "    \"\"\"Please explain the value of this text in basic terms like you're talking to a CEO. So, what? What's the bottom line here? \"\"\"\n",
    "    \"{text} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0bacb4-493b-45cf-99f6-1786dd7dea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(HIGH_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daec3194-0174-4d4b-ab40-1fe098fd26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc4109c-9e74-4dc5-9c4e-108f1966e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = runnable.invoke({\"text\" : text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47fd605-0709-47d2-953d-38d8bbba560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Bottom Line for CEOs:**\\n\\n**Large language models (LLMs)** are revolutionizing CAD software, enabling engineers to design and analyze products faster and more efficiently.\\n\\n**Key Benefits:**\\n\\n* **Conversational AI:** Engineers can describe their design needs in plain language, rather than navigating complex menus. This streamlines workflows and improves productivity.\\n* **Enhanced Design:** AI helps engineers create new designs and modify existing ones by understanding their intent. This accelerates the design process and reduces errors.\\n* **Automated Analysis:** AI can analyze designs for weight distribution, center of mass, and other factors. This provides valuable insights for decision-making and optimization.\\n* **Personalized Data Access:** Integrated data is made accessible through conversational AI, allowing engineers to tap into proprietary knowledge and specifications on-demand.\\n* **New Revenue Opportunities:** Conversational capabilities open up flexible pricing models, such as charging for queries or subscriptions. This monetizes valuable data assets.\\n\\n**Impact on Your Business:**\\n\\n* **Increased Productivity:** Engineers can design and analyze products faster, leading to reduced time-to-market and higher efficiency.\\n* **Improved Design Quality:** AI-powered analysis and optimization tools enhance the quality of designs, resulting in better products.\\n* **Competitive Advantage:** By adopting conversational CAD, your company can differentiate itself from competitors and attract top engineering talent.\\n* **Enhanced Customer Value:** Conversational CAD improves the user experience and provides valuable insights, increasing customer satisfaction and loyalty.'\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d70db-e967-4e08-983f-ba4c9b6c821b",
   "metadata": {},
   "source": [
    "### Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "485e0169-4fbb-4b4c-9706-5e4d04192069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analogy = (\n",
    "    \"\"\"Please give me an analogy or metaphor that will help explain this text to a broad audience!\"\"\"\n",
    "    \"{text}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24fdd3fa-2995-4ad1-a383-ee611e19adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(Analogy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aa3c595-9ce1-4ef1-92a1-83d97ec7fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1e6647b-a6bc-4363-9898-d83082f2308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = runnable.invoke({\"text\" : text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec9a3f08-32e7-4957-b310-da89a5d792fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Analogy:**\\n\\nImagine a CAD software as a sophisticated chef, and the engineer using it as a customer placing an order.\\n\\n* **Traditional CAD:** The chef follows a rigid menu, and the customer has to navigate complex options to specify their desired dish.\\n* **Conversational CAD:** The chef is now equipped with a language-understanding AI, allowing the customer to simply describe their culinary vision in plain English.\\n\\n**Metaphor:**\\n\\nConversational CAD is like a \"magic wand\" for engineers. Instead of manually inputting complex commands, they can simply describe their design needs in natural language, and the AI-powered CAD software instantly generates the desired results. This makes the design process more intuitive, efficient, and accessible.'\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69055c80-f430-4be8-b3d2-ef135aec80d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b40f4f3-c074-4702-97ff-671f55bc72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional \n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "from pydantic import BaseModel, Field, ConfigDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0167b4f7-855c-42dd-89e5-520010036ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experience(BaseModel):\n",
    "    # the title doesn't seem to help at all.\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    start_date: Optional[str] = Field(description=\"When the job or study started.\")\n",
    "    end_date: Optional[str] = Field(description=\"When the job or study ended.\")\n",
    "    description: Optional[str] = Field(description=\"What the job or study entailed.\")\n",
    "    country: Optional[str] = Field(description=\"The country of the institution.\")\n",
    "\n",
    "    \n",
    "\n",
    "class Study(Experience):\n",
    "    degree: Optional[str] = Field(description=\"The degree obtained or expected.\")\n",
    "    institution: Optional[str] = Field(\n",
    "        description=\"The university, college, or educational institution visited.\"\n",
    "    )\n",
    "    country: Optional[str] = Field(description=\"The country of the institution.\")\n",
    "    grade: Optional[str] = Field(description=\"The grade achieved or expected.\")\n",
    "\n",
    "    class Config:\n",
    "            arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "class WorkExperience(Experience):\n",
    "    company: str = Field(description=\"The company name of the work experience.\")\n",
    "    job_title: Optional[str] = Field(description=\"The job title.\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    first_name: Optional[str] = Field(description=\"The first name of the person.\")\n",
    "    last_name: Optional[str] = Field(description=\"The last name of the person.\")\n",
    "    linkedin_url: Optional[str] = Field(\n",
    "        description=\"The url of the linkedin profile of the person.\"\n",
    "    )\n",
    "    email_address: Optional[str] = Field(description=\"The email address of the person.\")\n",
    "    nationality: Optional[str] = Field(description=\"The nationality of the person.\")\n",
    "    skill: Optional[str] = Field(description=\"A skill listed or mentioned in a description.\")\n",
    "    study: Optional[Study] = Field(\n",
    "        description=\"A study that the person completed or is in progress of completing.\"\n",
    "    )\n",
    "    work_experience: Optional[WorkExperience] = Field(\n",
    "        description=\"A work experience of the person.\"\n",
    "    )\n",
    "    hobby: Optional[str] = Field(description=\"A hobby or recreational activity of the person.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbf2d41-6fd2-4164-927f-cc87893528c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cv(pdf_file_path: str) -> str:\n",
    "    \"\"\"Parse a resume.\n",
    "    Not totally sure about the return type: is it list[Resume]?\n",
    "    \n",
    "    \"\"\"\n",
    "    pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "    docs = pdf_loader.load_and_split()\n",
    "    # please not the function calling is not enabled for all models!\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "    chain = create_extraction_chain_pydantic(pydantic_schema=Experience, llm=llm)\n",
    "    return chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f09b329-dd00-4854-974d-02ce65e912de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class '__main__.Experience'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(parse_cv(\n\u001b[0;32m      2\u001b[0m         pdf_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenresume-resume.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m     ))\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mparse_cv\u001b[1;34m(pdf_file_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# please not the function calling is not enabled for all models!\u001b[39;00m\n\u001b[0;32m      9\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatGoogleGenerativeAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m chain \u001b[38;5;241m=\u001b[39m create_extraction_chain_pydantic(pydantic_schema\u001b[38;5;241m=\u001b[39mExperience, llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chain\u001b[38;5;241m.\u001b[39mrun(docs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\langchain\\chains\\openai_functions\\extraction.py:101\u001b[0m, in \u001b[0;36mcreate_extraction_chain_pydantic\u001b[1;34m(pydantic_schema, llm, prompt, verbose)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_extraction_chain_pydantic\u001b[39m(\n\u001b[0;32m     82\u001b[0m     pydantic_schema: Any,\n\u001b[0;32m     83\u001b[0m     llm: BaseLanguageModel,\n\u001b[0;32m     84\u001b[0m     prompt: Optional[BasePromptTemplate] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     86\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chain:\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a chain that extracts information from a passage using pydantic schema.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m        Chain that can be used to extract information from a passage.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPydanticSchema\u001b[39;00m(BaseModel):\n\u001b[0;32m    102\u001b[0m         info: List[pydantic_schema]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     openai_schema \u001b[38;5;241m=\u001b[39m pydantic_schema\u001b[38;5;241m.\u001b[39mschema()\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\main.py:197\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    190\u001b[0m         is_untouched(value)\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m         )\n\u001b[0;32m    195\u001b[0m     ):\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m ModelField\u001b[38;5;241m.\u001b[39minfer(\n\u001b[0;32m    198\u001b[0m         name\u001b[38;5;241m=\u001b[39mann_name,\n\u001b[0;32m    199\u001b[0m         value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m    200\u001b[0m         annotation\u001b[38;5;241m=\u001b[39mann_type,\n\u001b[0;32m    201\u001b[0m         class_validators\u001b[38;5;241m=\u001b[39mvg\u001b[38;5;241m.\u001b[39mget_validators(ann_name),\n\u001b[0;32m    202\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[0;32m    205\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:504\u001b[0m, in \u001b[0;36mModelField.infer\u001b[1;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[0;32m    501\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    502\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[1;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    505\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    506\u001b[0m     type_\u001b[38;5;241m=\u001b[39mannotation,\n\u001b[0;32m    507\u001b[0m     alias\u001b[38;5;241m=\u001b[39mfield_info\u001b[38;5;241m.\u001b[39malias,\n\u001b[0;32m    508\u001b[0m     class_validators\u001b[38;5;241m=\u001b[39mclass_validators,\n\u001b[0;32m    509\u001b[0m     default\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[0;32m    510\u001b[0m     default_factory\u001b[38;5;241m=\u001b[39mfield_info\u001b[38;5;241m.\u001b[39mdefault_factory,\n\u001b[0;32m    511\u001b[0m     required\u001b[38;5;241m=\u001b[39mrequired,\n\u001b[0;32m    512\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    513\u001b[0m     field_info\u001b[38;5;241m=\u001b[39mfield_info,\n\u001b[0;32m    514\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[1;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare()\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:550\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m ForwardRef \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m DeferredType:\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;66;03m# self.type_ is currently a ForwardRef and there's nothing we can do now,\u001b[39;00m\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;66;03m# user will need to call model.update_forward_refs()\u001b[39;00m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type_analysis()\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;129;01mis\u001b[39;00m Undefined:\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:756\u001b[0m, in \u001b[0;36mModelField._type_analysis\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morigin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are not supported.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    755\u001b[0m \u001b[38;5;66;03m# type_ has been refined eg. as the type of a List and sub_fields needs to be populated\u001b[39;00m\n\u001b[1;32m--> 756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_sub_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)]\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:806\u001b[0m, in \u001b[0;36mModelField._create_sub_type\u001b[1;34m(self, type_, name, for_keys)\u001b[0m\n\u001b[0;32m    791\u001b[0m     class_validators \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    792\u001b[0m         k: Validator(\n\u001b[0;32m    793\u001b[0m             func\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item\n\u001b[0;32m    802\u001b[0m     }\n\u001b[0;32m    804\u001b[0m field_info, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_field_info(name, type_, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config)\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\n\u001b[0;32m    807\u001b[0m     type_\u001b[38;5;241m=\u001b[39mtype_,\n\u001b[0;32m    808\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    809\u001b[0m     class_validators\u001b[38;5;241m=\u001b[39mclass_validators,\n\u001b[0;32m    810\u001b[0m     model_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config,\n\u001b[0;32m    811\u001b[0m     field_info\u001b[38;5;241m=\u001b[39mfield_info,\n\u001b[0;32m    812\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[1;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare()\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:555\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m Undefined \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulate_validators()\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\fields.py:829\u001b[0m, in \u001b[0;36mModelField.populate_validators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SHAPE_GENERIC:\n\u001b[0;32m    826\u001b[0m     get_validators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__get_validators__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    827\u001b[0m     v_funcs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[1;32m--> 829\u001b[0m         \u001b[38;5;241m*\u001b[39m(get_validators() \u001b[38;5;28;01mif\u001b[39;00m get_validators \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(find_validators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config))),\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[0;32m    831\u001b[0m     )\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidators \u001b[38;5;241m=\u001b[39m prep_validators(v_funcs)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_validators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\.conda\\envs\\LangChain2\\Lib\\site-packages\\pydantic\\v1\\validators.py:765\u001b[0m, in \u001b[0;36mfind_validators\u001b[1;34m(type_, config)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m make_arbitrary_type_validator(type_)\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno validator found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, see `arbitrary_types_allowed` in Config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: no validator found for <class '__main__.Experience'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "print(parse_cv(\n",
    "        pdf_file_path=\"openresume-resume.pdf\"\n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13235f96-c565-46ca-a882-e8eacc599fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
